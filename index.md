# Proposal
Please visit [Proposal](proposal.md).
# CheckPoint
Please visit [Check Point](checkpoint.md).

# Final Write Up

## Summary
We have implemented a distributed and parallel version of Latent Dirichlet Allocation (LDA) algorithm using OpenMPI library and OpenMP API. Our finalized version is 2x faster than [PLDA](https://code.google.com/archive/p/plda) when both lauching 64 processes, which is a parallel C++ implementation of LDA by Google. Our 64 processes implementation also achieves 20x speedup on its own, while 70x speedup against PLDA of a single process. Our test environment is in latedays cluster from 1 process to 64 processes, with at most 8 machines and 8 processes per machine. All of the experiments are run on two popular bag of words datasets [NIPS](https://archive.ics.uci.edu/ml/datasets/NIPS+Conference+Papers+1987-2015) and [NYTimes](https://archive.ics.uci.edu/ml/datasets/Bag+of+Words).

## Background

In natural language processing, LDA is a generative statistical model that extracts latent variables by observed variables. Specifically, LDA is a directed graphical model for topic discovery where each document is viewed as a topic distribution generated by Dirichlet prior. Then, each position can be assigned a topic by this document's topic distribution and word is generated according to the word distribution of assigned topic.
<div style="text-align:center"><img src ="./IntroToLDA.png" /></div>
### Generative process
Documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words. LDA assumes the following generative process for a corpus D consisting of M documents each of length N<sub>i</sub>.

1. Choose a multinomial topic distribution &theta; for the document (according to a Dirichlet distribution Dir(&alpha;) over a fixed set of K topics)
2. Choose a multinomial term distribution &phi; for the topic (according to a Dirichlet distribution Dir(&beta;) over a fixed set of N terms)
3. For each word position
	* choose a topic Z according to multinomial topic distribution &theta;.
	* choose a word W according to multinomial term distribution &phi;.

<div style="text-align:center"><img src ="./Smoothed_LDA.png" /></div>

### Implementation
The program receives a set of documents and a fixed topic number K as input. The output of LDA should be a topic-word table and document-topic table which represent the word distributions for all topics and topic distributions for all documents.

* Initialize topic distribution as uniform. Randomly assign each word in documents to one of the K topics.
* Calculate global distributions in topic-word and document-topic table.
* Iterate until convergence 
	* For each document and each word
		* Compute p(topic t \| document d, word w) = C * p(topic t \| document d) * p(word w \| topic t) according to global distributions for each topic.
		* Randomly assign one topic to current word according to above distribution.
		* Update global distributions.

The convergence is determined by the loglikelihood calclulated in each iteration of the corpus.

### Difficulty for parallelization
The key data structures are topic-word table and document-topic table. We can see that all the operations on these tables are +1 or -1 and in each iteration these tables will be modified. All the iterations are temporal related and can not be directly parallelized.

The most expensive parts of code are the calculation of topic distribution p(topic t \| document d, word w) and the sampling of topic according to this distribution. The sampling part is intrinsically sequential and can not be parallelized. The distribution calculation is too short to be parallelized unless there are millions of topics. This program is not restrictly data-parallel, but we can parallel on documents and loose some restrictions. The locality of the program is good because all the topic-related values are stored continuously and can be cached. However, when the corpus size or topic number is too large, the memory can not hold all the data structures.

## Approach
There are generally two scales to be considered when we want to gain a good speedup: topic number and corpus size. Our implementation tries to perform well when either scales up.

### sparseLDA
<div style="text-align:center"><img src ="./sparsity.png" /></div>
The above figure shows that both the topic-word table and document-topic table are very sparse. Thus, we can use hashmap to store the global tables if topic number is really large. Besides, we transform the calculation of the topic distribution into 3 subdivisions. They are called "topic-word" bin, "document-topic" bin and "smoothing only" bin respectively. Instead of sampling from original distribution, we sample from three bins now and we can expoit the sparsity to speedup the sampling. For the detailed implementation, please refer to [3].

### Distributed LDA
<div style="text-align:center"><img src ="./Basic_Idea.png" /></div>
<div style="text-align:center"><img src ="./sync.png" /></div>
<div style="text-align:center"><img src ="./async.png" /></div>
Tell us how your implementation works. Your description should be sufficiently detailed to provide the course staff a basic understanding of your approach. Again, it might be very useful to include a figure here illustrating components of the system and/or their mapping to parallel hardware.

Describe the technologies used. What language/APIs? What machines did you target?
Describe how you mapped the problem to your target parallel machine(s). IMPORTANT: How do the data structures and operations you described in part 2 map to machine concepts like cores and threads. (or warps, thread blocks, gangs, etc.)
Did you change the original serial algorithm to enable better mapping to a parallel machine?
If your project involved many iterations of optimization, please describe this process as well. What did you try that did not work? How did you arrive at your solution? The notes you've been writing throughout your project should be helpful here. Convince us you worked hard to arrive at a good solution.
If you started with an existing piece of code, please mention it (and where it came from) here.

## Results
We use NIPS and NYTimes datasets in our experiments. The basic information about the datasets is as follows:

|        | # Vocab           | # Doc  |
| ------------- |:-------------:| -----:|
| NIPS      | 11463 | 5811 |
| NYTimes   | 102660 |  299752 |

NIPS is relatively small while NYTimes is quite large. The different dataset size can help us to better measure the scalability of different implementation of LDA.

We run all experiments in the latedays cluster, each node has:

  * Two, six-core Xeon e5-2620 v3 processors (2.4 GHz, 15MB L3 cache, hyper-threading, AVX2 instruction support)
  * 16 GB RAM (60 GB/sec of BW)
  * MPI + OpenMP
 
There are different running setting combinations we used:

| # Process |  # Topic |             LDA Implementation            |    Dataset    |
|:---------:|:--------:|:----------------------------------:|:-------------:|
|   1 ~ 64  | 16 ~ 256 | sync, async, plda, sync(no sparse) | NIPS, NYTimes |

From the combination setting above, we choose our sequential version with sparseLDA as the baseline for our synchronous and asynchronous lda. This baseline runs ~250s on NIPS and ~1200s on NYtimes. For PLDA, we choose PLDA with one process as the baseline. This baseline runs ~600s on NIPS and ~6500s on NYtimes. When we run the LDA for different number of processes, we set the number of topic to be 128 on NIPS and 64 on NYtimes.

We measured our performance on three different metrics: the average iteration time, the total running time. This is because we can run LDA for fixed number of iterations or until it is converged. The total running time measures the time of convergence and the average iteration time measures the pure speedup.



Provide graphs of speedup or execute time. Please precisely define the configurations being compared. Is your baseline single-threaded CPU code? It is an optimized parallel implementation for a single CPU?
Recall the importance of problem size. Is it important to report results for different problem sizes for your project? Do different workloads exhibit different execution behavior?

IMPORTANT: What limited your speedup? Is it a lack of parallelism? (dependencies) Communication or synchronization overhead? Data transfer (memory-bound or bus transfer bound). Poor SIMD utilization due to divergence? As you try and answer these questions, we strongly prefer that you provide data and measurements to support your conclusions. If you are merely speculating, please state this explicitly. Performing a solid analysis of your implementation is a good way to pick up credit even if your optimization efforts did not yield the performance you were hoping for.
Deeper analysis: Can you break execution time of your algorithm into a number of distinct components. What percentage of time is spent in each region? Where is there room to improve?
Was your choice of machine target sound? (If you chose a GPU, would a CPU have been a better choice? Or vice versa.)


![](NIPS_Total_Time.png)          |  ![](NYtimes_Total_Time.png )
:-------------------------|-------------------------:


## References
[1] Blei, David M., Andrew Y. Ng, and Michael I. Jordan. "Latent dirichlet allocation." Journal of machine Learning research 3.Jan (2003): 993-1022.

[2] Newman, David, et al. "Distributed algorithms for topic models." Journal of Machine Learning Research 10.Aug (2009): 1801-1828.

[3] Yao, Limin, David Mimno, and Andrew McCallum. "Efficient methods for topic model inference on streaming document collections." Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2009.

[4] Li, Aaron Q., et al. "Reducing the sampling complexity of topic models." Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.

[5] Yu, Hsiang-Fu, et al. "A scalable asynchronous distributed algorithm for topic modeling." Proceedings of the 24th International Conference on World Wide Web. ACM, 2015.

[6] Yuan, Jinhui, et al. "Lightlda: Big topic models on modest computer clusters." Proceedings of the 24th International Conference on World Wide Web. ACM, 2015.

[7] Ian Porteous, David Newman, Alexander Ihler, Arthur Asuncion, Padhraic Smyth and Max Welling. Fast Collapsed Gibbs Sampling For Latent Dirichlet Allocation. In KDD’ 2008.

[8] David Mimno. Efficient Inference for Multinomial Mixed Membership Models.

[9] Aaron Q. Li, Amr Ahmed, Sujith Ravi, and Alexander J. Smola. Reducing the sampling complexity of topic models. In KDD’ 2014.